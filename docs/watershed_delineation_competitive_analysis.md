# Watershed Delineation Tools Competitive Analysis

*Extracted from: Watershed Delineation Tools Competitive Analysis.pdf*

## Page 1

Watershed Delineation Tools Competitive Analysis Introduction In this research, we present a comprehensive competitive analysis of leading watershed delineation tools – TauDEM, GRASS GIS (r .watershed), WhiteboxTools, SAGA GIS, and ArcGIS hydrology tools – to inform the design of a multi-tool benchmark framework. We focus on each tool’s latest stable releases (circa 2022– 2024) and consider their evolution and maturity. The analysis emphasizes mountainous semi-arid terrain of the Mountain West (e.g. Colorado, Utah, Wyoming) as our primary use-case, while ensuring findings generalize to other regions. We prioritize open-source solutions for accessibility, but also include ArcGIS for a complete landscape view. Our deployment context centers on desktop and HPC (high-performance computing) workflows, with consideration for containerization and cloud-readiness where applicable. Below, we detail tool capabilities and algorithms, summarize recent academic literature (2020–2024) on watershed delineation, discuss implementation and integration requirements, review performance benchmarking standards, and highlight emerging trends and future directions in this domain. (All information is referenced from technical documentation and recent research to ensure accuracy and currency.) 1. Tool Capabilities and Algorithm Support Flow Direction Algorithms: Each tool supports various flow routing algorithms for determining how water flows downhill on a DEM grid. The classic deterministic 8-direction (D8) method is universally supported. TauDEM provides both D8 and the D-Infinity (D∞) algorithm ; D∞ is Tarboton’s multiple-flow- direction approach that splits flow between downslope neighbors. GRASS GIS r.watershed supports single-flow (D8) and multiple-flow direction (MFD) modes . Its default is a form of MFD using an least-cost approach that distributes flow to all lower neighbors proportionally to slope, allowing more realistic divergent flow . WhiteboxTools offers a rich suite: D8 and D∞, as well as other MFD variants (e.g., Quinn et al. 1991, Freeman 1991 algorithms) and even triangular facet-based flow algorithms . SAGA GIS is similarly comprehensive – its flow accumulation module includes D8, Rho8 (Fairfield & Leymarie 1991), Braunschweiger Relief (a deterministic approach), D∞ (Tarboton 1997), traditional MFD (Freeman 1991), triangular MFD (Seibert & McGlynn 2007), and an MFD variant based on maximum downslope gradient (Qin et al. 2011) . ArcGIS (as of ArcGIS Pro) now supports D8, MFD, and D-Infinity within its Spatial Analyst Flow Direction tool – a notable expansion beyond the older D8-only approach. In summary, all tools can perform D8 routing; TauDEM, Whitebox, SAGA, and ArcGIS also implement advanced MFD/D∞ algorithms, whereas GRASS provides a robust MFD alternative via its internal algorithm. Depression Handling (Pit Filling vs Breaching): Handling DEM depressions (sinks/pits) is crucial for correct watershed delineation. Most tools require or offer explicit depression “filling” (raising pits to the spill point) or “breaching” (carving channels through barriers) as a preprocessing step. TauDEM requires a depressionless DEM; it includes a dedicated pit-filling tool (e.g. FillPits /PitRemove ) to produce a hydrologically conditioned DEM . WhiteboxTools provides both Fill and Breach operations (e.g. FillDepressions and BreachDepressions algorithms) to remove spurious sinks . Whitebox’s author advocates breaching in many cases to preserve terrain realism. SAGA GIS similarly offers sink12 3 34 56 7 89 10 1112 1



## Page 2

removal modules (notably the Wang & Liu 2006 algorithm) to fill depressions prior to flow calculations . In contrast, GRASS r.watershed does not require pre-filling – its least-cost flow algorithm effectively routes flow across depressions by “looking ahead” for an outlet . The GRASS approach simulates flow through sinks without explicitly altering the DEM, which is a unique advantage; even in single-flow (SFD) mode, GRASS can handle sinks without a separate fill step . ArcGIS traditionally requires using the Fill tool to remove sinks before delineation. The ArcGIS Flow Direction tool automatically treats single-cell sinks as noise and fills them on the fly , but larger depressions should be removed by running a fill operation beforehand. In summary, most tools recommend DEM pre-conditioning via fill/breach , except GRASS which integrates that logic internally . Stream Burning (Flow Enforcement): Stream burning (a.k.a. DEM reconditioning) is the practice of carving known stream networks into the DEM to enforce alignment of delineated streams with real rivers . TauDEM supports stream burning by allowing an “enforced” flow direction grid: users convert a vector stream network to a raster and burn it into the DEM before running TauDEM’s pit fill and flow direction functions . WhiteboxTools includes a dedicated “BurnStreams” tool that lowers DEM elevations along a provided stream polyline or raster by a specified amount or graded profile . Whitebox recommends performing a depression fill after burning streams to ensure consistency . SAGA GIS does not have a single built-in “burn streams” command, but users typically achieve it by subtracting elevations along stream vectors or using SAGA’s raster calculator . ArcGIS offers stream burning through the Arc Hydro toolkit’s DEM Reconditioning (AGREE) method or the HEC-GeoHMS extension . In ArcGIS Pro, one can also manually lower DEM cells along known streams (or use the “Flow Direction with Streams” setting if available in newer versions). GRASS GIS can accomplish stream burning with modules like r.carve (which cuts into the DEM along a stream vector) or by using a high cost for non-stream cells in its least-cost algorithm. In summary, all tools can incorporate known stream networks , though via different workflows: TauDEM and Whitebox have explicit support , ArcGIS and GRASS rely on separate pre- processing steps , and SAGA uses general raster operations . Stream burning is especially useful in flat areas or when aligning with known hydrography is critical . Performance Characteristics: The computational performance and scalability of these tools vary widely, especially for large DEMs (e.g., >10^8 cells). TauDEM is explicitly designed for high performance on multi- core and cluster systems – it uses MPI for parallel processing of DEMs . TauDEM operations (e.g. D8 flow accumulation) can be executed with mpiexec to distribute work across threads/cores, significantly speeding up large jobs . Notably, TauDEM’s MPI is usually configured for a single multi-core machine (shared-memory parallelism) without requiring networked clusters . GRASS r.watershed was re- engineered by Metz et al. (2010) for efficiency on large grids; it utilizes parallel processing via OpenMP threads and memory-optimized data structures . GRASS can handle quite large DEMs, but extremely massive datasets (multi-billion cells) may require tiling or using the older r.terraflow (which had an out-of-core algorithm) . Users have observed that r.watershed “struggles with big DEMs” around 5 billion cells and suggest subdividing the DEM in such cases . WhiteboxTools is implemented in highly optimized Rust code and is known for its speed. Users report that Whitebox’s hydrology tools “are very fast and work well on very large DEMs” . Whitebox leverages efficient memory handling and can be run as a command-line tool, in QGIS, or even from ArcGIS, making it versatile for different environments . However , WhiteboxTools currently runs single-threaded for most operations (no built-in parallel tiling), so its speed comes from algorithmic efficiency and low overhead. SAGA GIS performance is generally good for moderately sized DEMs, but many SAGA modules run single-core. For example, SAGA’s flow accumulation algorithms are not inherently parallelized, and processing a 100k x 50k (~5e9 cell) DEM in one go would be infeasible without tiling. SAGA does have some streaming capability (it can process line by line in certain13 14 4 1516 17 4 18 18 1920 21 22 1819 23 24 2526 27 28 2930 30 31 31 2



## Page 3

modules), and a “divide and conquer” tiling strategy can be used . ArcGIS Spatial Analyst historically had performance limits (ArcMap was 32-bit, single-threaded for many tools). ArcGIS Pro has improved this: the Flow Accumulation and related tools support multi-core parallelism – by default using ~50% of available cores – and will automatically chunk large rasters for processing . Esri notes performance gains on large datasets with parallel processing enabled, and provides environment settings to control the number of CPU cores and temp memory usage . Still, an open-source algorithm like TauDEM can often outperform ArcGIS on big data using HPC; one 2021 study found an automated outlet relocation algorithm (executed in parallel C++) delineated ~1,400 watersheds in 58 minutes at 90 m resolution, whereas ArcGIS took ~586 minutes for the same task – an order of magnitude difference. In summary, TauDEM is built for HPC scalability , GRASS and ArcGIS now exploit multi-core (to varying degrees), Whitebox and SAGA are very efficient but mostly single-core , and extremely large DEMs may require tiling or specialized GPU solutions (discussed later). Input/Output Formats and Coordinate Support: All tools ultimately work with raster DEM inputs and produce raster and vector outputs (streams, watershed polygons, etc.). TauDEM uses GDAL for I/O, so it supports common raster formats like GeoTIFF, and outputs TIFFs and shapefiles (e.g., for stream networks and watershed boundaries) . It expects DEMs in a projected coordinate system (linear units) for correct flow calculations (lat/long can be used but is not ideal due to non-uniform cell size). GRASS GIS requires importing data into its internal format (which can ingest GeoTIFF, ASCII grid, etc. via GDAL). GRASS outputs are in its own layer format but can be exported to GeoTIFF, shapefile, etc. GRASS handles any projection; notably, r.watershed results (like flow direction grid) use an encoded scheme (aspect directions) for D8 that can be interpreted as degrees CCW from east . WhiteboxTools has its own raster data structure and does not rely on external libraries for reading/writing GeoTIFF . It supports GeoTIFF and some simpler formats (e.g. ESRI ASCII grid), but the manual notes that not all exotic GeoTIFF variations are recognized . Whitebox outputs can be in GeoTIFF or its native .dep format; coordinate system handling is basic (it often assumes the DEM is in a meaningful linear coordinate system but does not deeply interact with projections beyond treating coordinate reference as metadata). SAGA GIS reads/writes many formats (through GDAL and native drivers). SAGA’s internal grid is a .sgrd binary, but users typically use the QGIS processing interface or exports to get GeoTIFFs out. SAGA expects projected coordinate data for hydrological tools (no specific limitation, but like others, using unprojected lat/long could distort flow results). ArcGIS is very flexible on formats: it can use any raster source supported by ArcGIS (GeoTIFF, ESRI grid, .CRF cloud raster format, etc.) and outputs either a layer in the map, a GeoTIFF, or a geodatabase raster . ArcGIS strongly encourages using a projected coordinate system (equal-area or equal-length) for flow analysis, and its documentation warns that using geographic coordinates can yield incorrect flow directions due to units . All tools allow output in the same coordinate system as input, and none are inherently tied to a specific projection , though using an appropriate projection (like UTM for regional studies) is recommended for accuracy. Installation Requirements & Dependencies: The complexity of getting each tool running differs. TauDEM is distributed as a set of command-line executables (C++ programs) plus (optionally) an ArcGIS toolbox interface . TauDEM requires an MPI library (Message Passing Interface) to be installed – on Windows the TauDEM installer bundles the Microsoft MPI (HPC Pack) libraries , and on Linux one would install MPICH or a similar MPI implementation . MPI setup is crucial; if not done with admin rights and PATH settings, “TauDEM does not run” as the documentation emphasizes . TauDEM also depends on GDAL for raster I/O. Once dependencies are in place, TauDEM can be used via command line on Windows or Linux; compiling from source is possible (C++ code is available) but the pre-compiled binaries are usually sufficient . GRASS GIS requires installing the GRASS software (available on all major OS). It’s a full GIS30 3233 3233 34 3524 36 3738 37 39 40 24 4142 4344 4527 3



## Page 4

suite (~100s of MB) with many dependencies (GDAL, PROJ, etc., usually handled by the installer). Using GRASS’s hydrology tools can be done via the GUI or by launching a GRASS session and running r.watershed . There is a slight learning curve to GRASS’s environment (mapset, region settings). Once installed, no additional dependencies are needed; GRASS is GPL-licensed (open-source). WhiteboxTools is very lightweight to install. It’s delivered as a single executable (~10 MB) or via a Python pip package (whitebox ), with minimal external dependencies . WhiteboxTools open-core is MIT licensed (permissive free software) . Some extended features (Whitebox Extensions) are proprietary add-ons, but all core hydrology functions are in the free open-source binary . Whitebox runs on Windows, Mac, or Linux. It can be invoked through command line, Python, or integrations (QGIS plugin, ArcGIS toolbox). SAGA GIS is an open-source GIS (GPL) that can be installed on Windows or Linux. It has a standalone GUI and also is accessible via QGIS Processing. Installing SAGA is straightforward (the Windows installer bundles needed libraries). On Linux, it’s often available via package managers. SAGA has some optional dependencies (for specific formats or toolboxes) but core hydrology tools work out-of-the-box. ArcGIS is commercial software; using ArcGIS Pro’s hydrology tools requires a valid license for ArcGIS Pro and the Spatial Analyst extension. Installation is the heaviest – Windows-only and several GBs – and it comes with Python (ArcPy) for scripting. In summary, open-source tools (TauDEM, GRASS, Whitebox, SAGA) are freely available, with Whitebox and SAGA being easiest to set up, TauDEM needing MPI configuration, and GRASS being heavier but comprehensive. ArcGIS is powerful but proprietary, costly, and limited to certain environments. The table below summarizes key features across the five tools: FeatureTauDEM (v5.3)GRASS GIS – r.watershedWhiteboxTools (Open Core v2.x)SAGA GIS (v7.x)ArcGIS (Pro 2.x / Arc Hydro) Flow Direction AlgorithmsD8; D-Infinity (MFD) .D8; MFD (slope- weighted least-cost ) . <br> No fill needed .D8; D∞; plus numerous MFD variants (Quinn, Freeman, etc.) .D8; Rho8; Braunschweiger; D∞; MFD; Triangular MFD; Qin et al. MFD .D8; MFD (Qin 2007 adaptive exponent); D∞ . Depression HandlingMust fill pits (separate step) – e.g. PitRemove .No sink filling required (algorithm routes through sinks) .Requires depression removal (tools: fill or breach) .Must fill sinks (tools: Wang & Liu fill, etc.) – otherwise flow may stop .Requires using Fill tool (small sinks auto-handled in D8) .4647 4849 4950 1 2 3 456 789 10 412 51 17 4



## Page 5

FeatureTauDEM (v5.3)GRASS GIS – r.watershedWhiteboxTools (Open Core v2.x)SAGA GIS (v7.x)ArcGIS (Pro 2.x / Arc Hydro) Stream BurningYes – burn streams into DEM via “enforced flow” grid .Indirect – use r.carve or preprocess DEM with known streams.Yes – dedicated BurnStreams tool (vector or raster input) .Indirect – lower DEM along streams via raster calc or separate tool.Yes – via Arc Hydro (AGREE) or DEM reconditioning workflow . Parallel ProcessingYes (MPI) – multi-core & cluster support; scale to very large DEMs .Yes (OpenMP) – multi- threaded; efficient on large DEMs .Not natively multi-core (fast single-core execution; can batch tasks).Not natively multi-core (single-core; use tiling or external parallelization).Yes (multi- core) – Spatial Analyst uses multiple cores (50% by default) . Typical PerformanceHigh performance on HPC/ cluster; designed for big data.Fast for moderate DEMs; may need tiling for 5B+ cell DEMs .Very fast algorithms (Rust); handles large DEMs in practice .Reasonable speed for ≤10^7 cells; large grids slow unless specialized GPU used.Improved in Pro; can still be slower than optimized open-source on huge jobs . Input/Output FormatsRaster: TIFF, etc. via GDAL; Vector: shapefiles .Any GDAL format in/ out (data imported to GRASS, exported after).Raster: GeoTIFF (with some limitations) or Whitebox .dep; Vector: shapefile, etc.Raster: native .sgrd or common formats via GDAL; Vector: shapefile.Many formats (GeoTIFF, Esri Grid, .CRF, FGDB); outputs raster or feature class. Platform & InterfaceWindows/ Linux. CLI driven; ArcGIS toolbox integration .Cross- platform. Use via GRASS shell or QGIS plugin.Windows/Mac/ Linux. CLI and Python API; QGIS & ArcGIS plugins .Windows/Linux. GUI or QGIS Processing or command line (saga_cmd ).Windows only (ArcGIS Pro Desktop or Enterprise). GUI and ArcPy (Python).1819 22 24 2832 3031 34 3537 4031 5



## Page 6

FeatureTauDEM (v5.3)GRASS GIS – r.watershedWhiteboxTools (Open Core v2.x)SAGA GIS (v7.x)ArcGIS (Pro 2.x / Arc Hydro) Installation & DependenciesRequires MPI library (MS-MPI on Windows, MPICH on Linux) ; plus TauDEM binaries. Open-source (MIT license).Install GRASS GIS (includes all deps). Open- source (GPL).Single executable or pip install. Minimal deps (no GDAL needed). Open- source (MIT) .Install SAGA (bundled deps). Open-source (GPL).Install ArcGIS Pro + Spatial Analyst license. Commercial proprietary. (Table: Comparison of major watershed delineation tools – algorithms, features, and technical characteristics, with sources.) 2. Academic Literature & Benchmarking (2020–2024) Recent peer-reviewed studies provide valuable insights into watershed delineation tool performance, accuracy, and best practices. We reviewed literature from 2020 onward, focusing on comparisons of algorithms and tools, evaluation metrics, and current challenges. Comparative Studies of Algorithms: A key topic in recent research is the evaluation of flow direction algorithms (D8 vs various MFD approaches) on accuracy and flow realism. Prescott et al. (2025) conducted a rigorous evaluation of flow-routing algorithms for computing contributing area on synthetic and real terrain. They found that Tarboton’s D∞ algorithm, despite its popularity, introduced directional biases (systematically favoring cardinal directions), making it “unsuitable for some standard applications” . Interestingly, the classical MFD algorithm by Freeman (1991) – often criticized historically for over- dispersing flow – was shown to be more accurate than D∞ in tests against analytical solutions and a shallow- water flow model . In other words, MFD outperformed D∞ for contributing area calculations under many conditions, revising the conventional wisdom. Prescott et al. even introduced a new algorithm, IDS (Iterative Depth Slope) , which uses an iterative, physically-based approach (Manning’s equation for flow partitioning) to route water; IDS further improved accuracy in cases with substantial differences between water surface slope and bed slope . This indicates active research interest in developing algorithms beyond D8/MFD/D∞ to better capture flow physics and reduce uncertainty. Another study in 2021 proposed D8-LTD , an improved single-flow algorithm, and FMFD (an enhanced MFD), finding these performed best on certain complex surfaces (e.g., high-frequency terrains) – highlighting that even within SFD or MFD classes, algorithmic tweaks can yield accuracy gains . Overall, the literature suggests that no single flow algorithm is universally superior : D8 remains computationally efficient but can produce unrealistic parallel flow paths on smooth slopes , while MFD variants offer more realistic dispersion at the cost of potential overestimation of drainage density. Modern comparisons (2020+) show context matters : for example, on convergent terrain or large watersheds, D8 may under-represent contributing areas, whereas on divergent slopes, naive MFD can spread flow too thin. These findings underscore the importance of tools supporting multiple algorithms so the user can choose appropriately or even compare outcomes.43 44 49 5253 52 53 5455 5657 58 6



## Page 7

Tool Comparison and Accuracy Benchmarks: Surprisingly few recent papers directly compare entire software packages (TauDEM vs ArcGIS vs GRASS, etc.), but some studies and reports do offer clues. A 2021 study by Xin et al. introduced an Automatic Outlet Relocation (AOR) algorithm to improve watershed delineation speed and accuracy . They compared AOR’s delineations to ArcGIS’s standard watershed tool over 1,398 basins: ArcGIS achieved ~81.3% accuracy (presumably measured as agreement with a reference or with all outlets correctly captured) whereas the AOR method reached 94.1% . This indicates that ArcGIS’s delineation was only ~81% accurate in that large-sample test, leaving substantial room for improvement – many basins were delineated incorrectly due to outlet placement issues that AOR corrected. The AOR study also highlighted performance: ArcGIS took nearly 10 hours (586 minutes) to delineate ~1,400 watersheds, whereas AOR did it in under 1 hour . While AOR is a specific research algorithm (not yet a standard tool), the study’s metrics provide a baseline: ArcGIS (Spatial Analyst) can delineate large numbers of watersheds with about 80–90% accuracy under automated workflows , and parallel algorithms (like TauDEM or AOR’s C++ code) can dramatically accelerate the process . Other studies have looked at how different tools or DEM sources affect delineation. For instance, some papers compare watersheds derived from various DEM resolutions or sources (SRTM vs LiDAR, etc.) using TauDEM or ArcGIS, evaluating delineation differences in terms of area or stream network match . These often report that higher-resolution DEMs yield more detailed (but potentially more noisy) drainage networks , and that filling or not filling depressions can change the total watershed area by a few percent. A 2020 case study in Johor , Malaysia (Rahim et al., 2020) examined open-source vs ArcGIS delineation using ASTER vs SRTM DEMs . While that study was more about DEM accuracy, it noted that with proper conditioning, open-source tools produced watershed boundaries comparable to ArcGIS’s, with differences mainly arising from DEM errors rather than tool algorithm issues . This suggests that when using similar flow algorithms and DEM data, modern tools tend to produce consistent watershed boundaries – a reassuring point for our benchmark. Evaluation Metrics and Validation Methods: Standard evaluation of watershed delineation accuracy can be tricky, since “ground truth” watershed boundaries are not directly measurable except in small basins where one can survey ridgelines. Common validation approaches include: comparing automated delineations to established watershed datasets (e.g., the USGS Watershed Boundary Dataset or HydroBASINS for global basins) and computing overlap statistics, or checking if known stream gauge catchment areas match the delineated areas. Metrics used range from area-based measures (e.g., percent area overlap, or ratio of delineated area to reference area) to boundary agreement metrics (like mean distance between delineated divide and true divide, or a coincidence ratio) . In studies like the AOR paper , accuracy was reported presumably as a percentage of basins correctly delineated within tolerance . Some works use cell-by-cell classification metrics (treating watershed delineation as a binary classification of grid cells inside vs outside the basin): from that perspective, one can compute something akin to overall accuracy, Jaccard index, or Cohen’s kappa comparing two basin maps . For example, if a reference watershed raster is available, one can calculate the percentage of cells that are the same in the automated result vs reference (though this heavily weights larger areas). Boundary precision can be assessed by sampling points along one boundary and measuring distance to the other boundary – effectively evaluating how far off the delineated divides are. Another approach is to compare derived stream networks : if the delineation is good, the extracted streams (flow accumulation above threshold) should align with known river maps. Metrics like percentage of known streams captured, or root-mean- square distance of delineated stream paths to blue lines on a map, have been used. In summary, there isn’t a single “industry standard” metric for watershed delineation accuracy, but area overlap and stream59 59 34 59 34 6061 62 63 64 59 6566 7



## Page 8

alignment are common criteria . Our benchmark will likely incorporate multiple metrics to capture different aspects of performance (e.g., overall area correctness and local boundary errors). Current Challenges & Limitations (from literature): Researchers have noted several persistent challenges in automated watershed delineation: - Flat terrain and pits: Flat areas and extensive depressions (like large lakes or wetlands) pose difficulties. Traditional algorithms (like the pure D8 as in older ArcGIS) can fail to delineate watersheds correctly if the divides are extremely flat or contain sinks. For example, GRASS GIS documentation cites that ArcGIS’s older algorithm (akin to r.terraflow ) “fails under [conditions of flat, forested divides]” while r.watershed succeeds . Large depressions can either terminate flow (if not filled) or , if filled, create unnaturally large flat surfaces. Recent research addresses this by “handling lakes explicitly” – e.g., a 2022 study introduced a web-based tool for watershed delineation that considers lakes as separate elements , delineating lake catchments and outflows to integrate lake routing into watershed definitions . This approach prevents large lakes from either breaking the watershed or being lost in a fill-and-flow process. - Urban and Karst terrains: Highly altered landscapes (urban environments with stormwater infrastructure) and karst regions (subsurface drainage) remain problematic, as standard DEM- based flow algorithms assume surface flow. Academic literature suggests augmenting DEMs with “punctures” at storm drain inlets or karst sinkholes to simulate flow sinks . Some GIS approaches incorporate known infrastructure (e.g., culverts, drains) to enforce realistic flow paths, but this is not yet automated in most tools. - Threshold selection and network definition: Many studies point out that the choice of stream initiation threshold (minimum upslope area to consider a cell part of a stream) greatly influences watershed outputs (especially the number and detail of tributaries) . There is no single optimal threshold; some research tries dynamic or physiographically determined thresholds, but the lack of a standard means tool comparisons must normalize this parameter . Best practice is to calibrate threshold such that extracted streams match known perennial streams in a basin . For benchmarking, one might need to evaluate multiple threshold levels. - Computational limitations: As DEM resolutions increase (e.g., 1–3 m LiDAR datasets), processing these at watershed-scale becomes memory and time intensive. Researchers have demonstrated GPU-accelerated solutions to this (discussed in Emerging Trends below), but many operational tools still struggle with huge grids. The literature acknowledges that multi-scale or multi-resolution approaches might be needed – delineating at coarser resolution for large basins, then refining sub-basins with finer data for detail. - Validation and uncertainty: A challenge noted is the lack of uncertainty quantification in delineation. Traditionally, a watershed boundary is a deterministic line from a single DEM. However , if the DEM has vertical error , the exact position of the divide can be uncertain. Recent academic work has begun to quantify this by perturbing DEM elevations within their error margin and re- delineating (Monte Carlo simulation) . For instance, a 2023 study by Koytrakis et al. built a GPU program to perform “DEM uncertainty-aware drainage basin delineation” , essentially running thousands of Monte Carlo simulations of slightly perturbed DEMs to map the probability distribution of watershed boundaries . This identifies where divides are robust versus where small elevation changes cause big shifts. Such work is cutting-edge and not yet incorporated into mainstream tools, but it highlights that our benchmark could include analyses of sensitivity (though full Monte Carlo may be beyond scope, awareness of this uncertainty is important). Best Practices for Tool Selection and Validation: Drawing from the literature and documented case studies, some general guidance emerges: - Use multiple tools/algorithms for cross-validation when possible. If two different algorithms (say D∞ vs MFD, or TauDEM vs GRASS) yield the same watershed boundary, confidence in the result increases. Conversely, discrepancies might flag areas of concern (flat regions, ambiguous divides). - Leverage high-quality reference data : e.g., compare delineations against known hydrographic maps (NHD streams, known watershed outlets). Many studies overlay automated2867 6869 70 71 72 73 7473 8



## Page 9

streams on blue-line maps to visually verify correctness, a step we should include in our validation framework. - Ensure consistent preprocessing : differences in whether pits are filled or not can lead to apples-to-oranges comparisons. Literature recommends standardizing DEM conditioning across tools (e.g., fill all DEMs with the same method externally if one tool cannot fill internally) to isolate algorithm differences . - Consider the scale and purpose : for instance, Tarboton (1997) noted D8 is prone to aligned parallel streams on convex hillslopes , which may or may not matter depending on if you care about micro-channel alignment or just overall basin area. Best practice is to pick algorithms appropriate to the terrain: MFD for broad hilltops or divergent terrain, D8 or D∞ for sharper terrain or if one needs discrete stream networks, etc. - Validate end-to-end : Instead of just checking the boundary, run a simple hydrologic model (or even just check drainage area values) at known gauged points. If the delineated drainage area for a river gauge matches the published area of that basin (often available from agencies), that’s a strong indication the watershed was correctly delineated. This method is often used in practice for QA. - From the academic perspective, reproducibility and open tools are valued. Studies often use open- source tools (TauDEM, GRASS, Whitebox) so results can be replicated and built upon. Our benchmark aligning with open-source ensures it can be used widely for validation studies. In summary, the recent academic literature underscores that watershed delineation is a mature but still evolving field. Fundamental algorithms are being refined (e.g., addressing D∞ limitations ), and new methods are tackling previously hard problems like uncertainty and large-scale automation . These insights will guide our benchmark design – ensuring we test a variety of algorithms, incorporate rigorous validation metrics, and stay aware of the common pitfalls identified in research. 3. Implementation and Integration Requirements Implementing multiple delineation tools in a single benchmark framework presents practical challenges. Here we analyze the requirements for installing, interfacing with, and running each tool, including handling large datasets, available APIs, containerization, and known failure modes. Programming Interfaces (CLI vs API): All five tools can be executed via command-line interfaces, which is likely how a benchmark would orchestrate them. TauDEM consists of command-line programs (e.g., PitRemove , D8FlowDir , AreaD8, etc.) that can be called from scripts . TauDEM does not have an official high-level Python API, but integration is feasible by invoking the CLI with subprocess calls or through existing wrappers (for example, some QGIS plugins or GDAL scripts exist to call TauDEM). One must ensure the MPI execution ( mpiexec -n <cores> <ToolName> ... ) is included in calls to utilize parallelism . GRASS GIS offers both CLI and a Python API. One approach is to call GRASS modules via the grass.script library (for example, using grass.script.run_command("r.watershed", ...) ). Alternatively, one can invoke r.watershed through system calls or through QGIS’s processing framework. Using the Python API (PyGRASS or GrassScript) is efficient if the benchmark can run in a GRASS session – it avoids overhead of launching the program for each command. WhiteboxTools was designed with integration in mind: it provides a Python API (whitebox Python package) that wraps calls to the WhiteboxTools executable . For example, one can do wbt = WhiteboxTools() in Python and then call wbt.d8_flow_accumulation(...) directly . This makes it straightforward to incorporate Whitebox into a Python-based benchmark. It also has R and even Nim interfaces, but Python will suffice for us. SAGA GIS can be controlled via its command-line tool saga_cmd . Many of SAGA’s hydrology functions (e.g., the flow accumulation module) can be called with a single saga_cmd call and a series of parameters . There isn’t a native Saga Python API, but integration can use QGIS’s475 58 52 7334 7677 78 7980 7980 8182 9



## Page 10

processing API (which internally calls saga_cmd) or call saga_cmd directly. The QGIS Processing framework might be too heavy for our needs; simpler is to run saga_cmd with the appropriate tool ID and arguments (which are documented in SAGA’s manual) . We should note that managing SAGA versions is important – QGIS often ships a specific version; our benchmark should fix a version for consistency. ArcGIS provides ArcPy, a rich Python API, to call geoprocessing tools. If ArcGIS is to be included in an automated benchmark, one would use ArcPy’s FlowDirection , FlowAccumulation , Watershed tools with the appropriate environments. However , using ArcPy requires an ArcGIS license and a Windows environment. Another approach is to use Esri’s command line via ArcGIS Pro’s Project Package, but that’s less common. Given the complexity and licensing, we might treat ArcGIS runs as manual or separate if needed. In summary, Python integration is readily available for GRASS, Whitebox, and ArcGIS , and possible via CLI for TauDEM and SAGA. A unified Python workflow is achievable, calling each tool’s executable or library in turn. Memory Management and Large Data Handling: Handling large DEMs is a core requirement for our benchmark. Each tool’s memory approach differs: - TauDEM loads DEM data into memory (distributed across MPI processes if used). It doesn’t implement tiling itself; it relies on MPI parallelism to partition work. Thus, to process a huge DEM on a single machine, having sufficient RAM for the entire DEM plus some overhead is needed. If memory is insufficient, TauDEM might fail or resort to disk swapping (if OS allows). There is no explicit out-of-core algorithm (unlike GRASS’s older TerraFlow which used external memory), so memory can be a bottleneck. Practically, using multiple processes can help if each process gets its own memory partition, but on a single machine it’s the same memory pool. For enormous data, one could manually split the DEM and run TauDEM on tiles, then merge results (but merging watershed boundaries is non-trivial). Still, TauDEM’s efficient C++ and use of multiple cores give it a strong edge for large data within available RAM. - GRASS r.watershed is optimized to reduce memory usage compared to older methods. Metz et al. (2011) report that it can handle large areas by using a least-cost search algorithm that doesn’t require storing huge intermediate matrices . GRASS also uses row-by-row processing to some extent. The module has a parameter for memory usage where the user can set how much RAM to allocate. If a DEM is too large for available memory, GRASS may throw an error or slow down drastically. In such cases, the user can reduce the region resolution or split the area. There is also the r.terraflow module (SFD only) which specifically was designed for huge DEMs using external memory (it can handle hundreds of millions of cells by spilling to disk). However , r.terraflow has its limitations (only D8, and known to produce some errors under certain conditions ), so it’s not the first choice unless absolutely needed. One advantage: GRASS can operate in a Linux environment where large memory machines (or even cloud VMs with 128+ GB RAM) can be used, and it will utilize that if configured. - WhiteboxTools documentation gives a heuristic for memory: approximately 4x the uncompressed size of the input raster should be available as a minimum . For example, a 1 GB DEM file might need ~4 GB RAM to process, because Whitebox converts data to 64-bit floats in memory, possibly doubling or quadrupling the size depending on original data type . Additionally, Whitebox often needs to allocate an output raster in memory of equal size before writing it out . Thus, an operation could need ~2 * grid_size in memory. If memory is insufficient, Whitebox might crash or raise an error (it does not implement tiling or disk caching internally). The user can sometimes work around moderate memory limits by using Whitebox on smaller tiles or using its streaming for certain tools (though most hydrology tools do not stream). The Limitations section of the manual explicitly notes that some large GeoTIFFs might be problematic, and that ensuring no other heavy processes and having enough RAM is important . In practice, Whitebox has been successfully used on LiDAR-scale DEMs (e.g., 1m DEM of several thousand sq km) by powerful machines. For our benchmark, if memory is an issue, we may restrict test DEM size or use a subset. - SAGA GIS historically loads entire grids into memory (SAGA data structures). It doesn’t automatically tile. However , SAGA modules like “Flow8384 28 85 8687 8889 90 3889 10



## Page 11

Accumulation (Top-Down)” could be modified to read row by row; it’s not clear if the current version does this. The presence of a “Step” parameter in SAGA’s flow accumulation tool hints it processes the DEM in passes , but it likely still requires full grid access. SAGA can handle moderately large grids (tens of millions of cells) but might struggle with multi-billion cell cases. Running SAGA in a 64-bit environment with ample RAM is necessary for large tasks. Like others, if memory fails, it might crash or hang without a clear message. - ArcGIS uses a tiled processing and caching strategy for large rasters. ArcGIS Pro (64-bit) can handle quite large datasets by reading/writing temporary chunks to disk as needed (especially with the enhanced CRF raster format and the parallel processing environment) . It will also create pyramids (overviews) for large outputs which helps with display but not directly with processing memory. ArcGIS’s help suggests that by default it will split tasks if the raster > 5,000 x 5,000 cells . It also mentions the use of a temp directory for chunk processing . This indicates ArcGIS is fairly robust in not running out of memory – it may trade speed by doing more disk I/O for extremely large data. For example, if one tries to run flow accumulation on a 30m DEM of an entire country, ArcGIS will likely tile it internally. The downside is it may be slow and the user has less manual control over how tiling is done (besides setting environment variables for tile size or parallel factor). Containerization and Deployment: To ensure reproducibility and ease of use on various systems (local desktops, HPC clusters, or cloud), containerization is a key consideration. TauDEM can be containerized – in fact, there are public Docker images (e.g., docker-taudem on GitHub) that bundle TauDEM with MPI in a Linux container . Using TauDEM via Docker/Singularity on an HPC could simplify MPI configuration and ensure the correct environment. GRASS GIS also has official Docker images from the GRASS community (often used in continuous integration). A container would include GRASS and dependencies, allowing us to run grass ... -c "r.watershed ..." in an isolated environment. WhiteboxTools is straightforward to containerize since it’s just a single binary and optional Python. One could use a lightweight base image (alpine or debian) and add the WhiteboxTools binary, or use the Python pip to install whitebox . Because Whitebox has no special system requirements, a container mainly helps with consistency of version. SAGA GIS can be put in a container (e.g., OSGeo/Ubuntu base with SAGA installed). However , note that SAGA’s GUI won’t be needed; we’ll use saga_cmd, which works fine in a headless container . SAGA’s only trick in a container is ensuring the locale or any graphics libs it might call are set up; but since saga_cmd is CLI, it’s usually fine. ArcGIS is an outlier – it does not support Linux containers (ArcGIS Pro is Windows-only, though ArcGIS Enterprise has some Linux components). There is currently no official Docker for ArcGIS Pro; running ArcGIS in a container is not straightforward due to licensing and OS constraints. We likely will not containerize ArcGIS; instead, if ArcGIS benchmarks are needed, they may run on a dedicated Windows machine or VM. Overall, focusing on open-source, we can have a Docker/Singularity multi-tool image that includes TauDEM, GRASS, Whitebox, and SAGA, orchestrated by a Python script. This ensures the environment is consistent. Containerization also helps with cloud deployments – for example, running the benchmark on Kubernetes or in cloud VMs becomes easier if everything is packaged in one image. We should also consider snapping to versions : e.g., TauDEM 5.3, GRASS GIS 8.2, WhiteboxTools 2.4.0, SAGA GIS 7.9.0 (for example) – using specific versions in containers means results will be reproducible in the future. Configuration Parameters and Performance Impacts: Each tool has numerous tunable parameters; some key ones that affect performance and results: - Stream initiation threshold: as mentioned, the minimum contributing area to define a stream (or in GRASS, the threshold for exterior watershed basin size in cells) is crucial . Lowering this threshold produces more streams (finer drainage network) and smaller sub-watersheds, which can dramatically increase runtime and memory use . For example, GRASS8491 3233 32 92 93 71 71 11



## Page 12

warns that “low threshold values will dramatically increase run time” . TauDEM’s StreamNet function similarly will take longer if one sets a very low area threshold because it has more stream cells to evaluate. So, in benchmarking, we must decide on a consistent threshold or perhaps test a couple of values to see tool scalability. - Convergence factor (for MFD algorithms): Tools like GRASS and SAGA allow adjusting how flow is shared in MFD. SAGA’s default convergence factor is 1.1 for its MFD , and GRASS’s MFD behaves as if a convergence factor is in effect (though not exposed directly in r.watershed ). A higher convergence factor concentrates flow more like D8, which could speed up processing slightly (less spreading means fewer cells get incremental flow contributions) but also changes results. For fairness, we’d likely use default settings for each tool’s MFD. - Edge handling: ArcGIS has a parameter “force edge cells to flow outward or not” . If not forcing outward (default), some edge cells can drain inward if surrounding terrain is higher . This can create artificially large watersheds at edges or undefined areas. Other tools implicitly either force edges out or mark them differently. We should ensure a consistent approach (probably let edge cells flow outward to avoid incomplete basins at dataset borders). ArcGIS’s default (NORMAL) is to allow edge inflow if justified , but for standalone basins analysis, one might want to force edges out to treat dataset boundary as a watershed boundary. This parameter might not hugely affect performance, but it does affect results near edges. - Parallel settings: For TauDEM, the -n (number of processes) in mpiexec is key for performance . We should test with varying core counts. ArcGIS’s parallel factor environment can be set to use more or fewer cores . GRASS’s OMP threads count is usually set via an environment variable ( OMP_NUM_THREADS ). We’ll need to tune these for equal footing (e.g., test all tools on 8 threads if possible, noting some can’t use them). This isn’t a “parameter” in the algorithmic sense but is important for benchmarking fairness. - Specific tool parameters: TauDEM’s DropAnalysis has parameters M and Y for its stream delineation method (longest path and area relationship) ; these are advanced and usually default. Whitebox’s breach tools have a max breach depth parameter , etc. For our purpose, we likely stick to default configurations unless a tool’s default is non-comparable (e.g., Whitebox’s “BreachDepressionsLeastCost” vs filling – we might just do fill for all to be uniform). Documented Failure Modes and Edge Cases: Each tool has known scenarios that can cause errors or suboptimal results: - TauDEM : If MPI is not set up correctly, TauDEM will simply not run (common user issue on Windows is forgetting to register mpiexec or not running as admin ). In use, a known edge case is when a DEM has no outlet (endorheic basin) – TauDEM will delineate the internal watershed but one must be careful interpreting results. Another issue is very large flat lakes: TauDEM’s pit filling will turn them into flat surfaces which then have undefined flow direction (it might mark them as “ocean” if using depression mask, or all flow directions = 0 meaning no downslope neighbor). TauDEM expects the user to enforce streams or outlets in such cases. Memory-wise, a failure occurs if you attempt to run on more MPI processes than available cells (rare) or if the machine runs out of memory (which can cause MPI to hang or crash). - GRASS r.watershed : A common edge case is when the region has no valid outlet (all boundaries are higher terrain). GRASS will mark those areas as having negative drainage directions (flow leaving the region) . Not a failure per se, but the result is that some basins are incomplete. One must ensure the computational region is set properly and includes the outlets or uses the flag for internal depressions ( -m flag if wanting to identify depressions). Also, extremely large regions with very low threshold can exhaust memory; the module might abort with a memory allocation error if it can’t allocate needed arrays (especially if threshold is so low that it tries to label millions of tiny basins). - WhiteboxTools : Because it’s relatively new, some edge cases revolve around data formats. If the input DEM has an uncommon projection or an unusual data type, Whitebox might not read it correctly (since it has a custom GeoTIFF reader) . The workaround is usually to convert the DEM to a simpler format (GeoTIFF uncompressed, or ASCII grid). We should be mindful to provide simple GeoTIFFs. Also, if there are NoData holes in the DEM, some Whitebox operations might propagate those differently. Whitebox will fail if the output path has71 94 3995 39 25 33 96 4344 9798 3799 12



## Page 13

special characters like apostrophes (documented in limitations) . On the algorithm side, Whitebox’s breaching algorithm might create unnatural “trenches” across ridges if misused (it’s powerful but can be overzealous). The least-cost breaching ensures minimal elevation modification, but if a user sets it to breach very deep pits, it can cut through terrain in ways a fill wouldn’t – a consideration when comparing results. - SAGA GIS : Some SAGA hydrology modules have quirks. For example, if a DEM has multiple adjacent flat cells, certain older algorithms could get stuck in infinite loops of flowing back and forth (there were bugs about this in the past). The current algorithms try to route across flats by either identifying sink routes or requiring a prior fill. If the user forgets to fill sinks and uses an algorithm that doesn’t implicitly handle them, SAGA might produce incomplete flow accumulation (e.g., areas with no outflow just show zero accumulation). Also, SAGA’s tools often output intermediate data (like “sink route” grids) that if not interpreted correctly, could confuse results. Another edge: SAGA uses a specific encoding for flow directions (0-7 for cardinal/intercardinal directions in D8, with 8 sometimes meaning undefined). If we compare D8 outputs, we need to map these encodings properly. - ArcGIS : Failures in ArcGIS are less about crashes (though it can crash on very large jobs) and more about misinterpretation. For example, ArcGIS will identify “sinks” (undefined flow direction cells) and can fill them with the Sink tool or the Fill tool. If one runs FlowDirection without Fill, it will mark sinks but not resolve them; subsequent FlowAccumulation can get stuck (endless loop) if a circular flow exists . Indeed, Esri notes: “if flow direction contains a loop, Flow Accumulation will never finish” . This is why ensuring pits are handled is essential in ArcGIS – a user pitfall (pun intended). Also, ArcGIS has a limit on the number of unique watershed zones it can delineate in one go; if one tries to delineate thousands of watersheds at once with the Watershed tool, it might run into internal limits or slowdowns. The AOR paper effectively noted ArcGIS was much slower for thousands of outlets . So large-scale multi-outlet delineation is a challenge. Considering these, our integration roadmap will need robust error handling: check for successful execution of each tool, verify outputs (e.g., no null or all-zero results), and log any discrepancies. We should run small test cases first to validate each tool’s pipeline in our environment. Using containerization can minimize environment-related failures (like missing libraries or wrong versions). In conclusion for this section, from an implementation standpoint we will: - Use Python to orchestrate calls to each tool (leveraging APIs for Whitebox/ArcGIS, and CLI for TauDEM/SAGA/GRASS). - Containerize the environment to include all necessary tools (except possibly ArcGIS) to simplify deployment on HPC or cloud. - Anticipate memory needs by possibly limiting input DEM size in tests or ensuring our test machine has adequate RAM. - Standardize preprocessing (like DEM projection, initial fill) to avoid inconsistent inputs. - Include checks for each tool’s output and clear documentation of how to reproduce the run (including parameter settings like threshold, convergence, cores used, etc.). This careful planning will set the stage for actually performing the multi-tool benchmark in a reliable, repeatable way. 4. Performance Benchmarking and Validation Framework To objectively compare the tools, we need a well-defined benchmarking and validation framework. This includes standard datasets for testing, performance metrics, and quality assessment procedures rooted in academic standards. Standard Test Datasets: Establishing common test DEMs is critical. We will select a range of DEM datasets that reflect typical use cases: - Mountain West DEM: Our primary dataset will be a high-resolution DEM100 101 102 34 13



## Page 14

from the Mountain West region (e.g., a 10 m or 30 m DEM covering a mountainous watershed in Colorado). This matches our focus terrain – mountainous, semi-arid. A specific example might be a HUC-8 watershed in Colorado for which we have known outlet locations and possibly a reference boundary (from USGS). This dataset will test how tools handle steep terrain with deep valleys. - Varied Terrain DEM: To ensure broader applicability, we include a DEM of temperate terrain with rolling hills (e.g., a portion of the Appalachian region or a mixed relief area). This can test performance on gentler slopes with more depressions and vegetation artifacts (to simulate conditions where algorithms like GRASS’s are advantageous ). - Flat Terrain or Coastal Plain DEM: As a stress test for depression handling, a flat or low-relief area with many wetlands (or an area with a large lake) could be used. For example, a portion of the Minnesota prairie pothole region or a coastal area in Louisiana. This can evaluate how tools manage many small sinks or a huge flat water body (some may require fill, others not). - Synthetic DEMs: Inspired by academic practice, we can include some synthetic surfaces where the “correct” contributing area can be analytically derived . For instance, a simple tilted plane (where flow accumulation should increase linearly downslope) or a cone-shaped mountain (radial flow). Synthetic tests can reveal algorithm differences clearly (e.g., Prescott et al.’s finding that D∞ biases appear on an analytical cone surface ). These small grids also run quickly, allowing micro-benchmarks of algorithm efficiency without I/O overhead. - Large DEM for scaling: Perhaps one large dataset (if resources allow) such as a 1m LiDAR DEM of a smaller catchment or a 30m DEM of an entire state. This would test extreme performance: which tools complete, how memory usage scales, etc. However , this might be optional if it exceeds practical time limits. We will obtain these DEMs from authoritative sources (USGS 3DEP for US regions, etc.) and ensure they are preprocessed identically (same projection, void-filled if necessary). For reference-based validation, we will gather any available “ground truth” such as published watershed boundaries (e.g., from the Watershed Boundary Dataset (WBD) for the US, which provides hydrologist-curated watershed polygons). These can serve as reference for comparing automated outputs. Additionally, we may use HydroBASINS (a global dataset of basin delineations) for any global tests, as it represents a community standard for basin boundaries at multiple scales. Using standard datasets aligns with practices in literature where, for example, many studies test on well-known basins (like the Mississippi sub-basins, etc.) to allow result comparison. Performance Metrics: We will measure both computational performance and accuracy/quality performance: - Computational metrics: runtime (CPU time and wall-clock time) for each tool on each dataset; memory usage if possible (peak RAM); and for parallel tools, speedup with multiple cores. We might create a matrix of runtime vs DEM size vs number of cores to see scalability. For example, measure how TauDEM scales from 1 to 8 cores on a given DEM, or how ArcGIS with parallel processing on vs off behaves. These timings are straightforward to capture via logs. We will also note any pre-processing time (e.g., if a tool needs a separate fill step and how long that takes). If a tool fails on a dataset (e.g., runs out of memory), that’s a critical performance data point as well. - Accuracy/quality metrics: as discussed, we’ll compare delineated watershed outputs to references. Specifically: - Area overlap : For a given outlet (or set of outlets), calculate the overlap between the tool’s watershed polygon and the reference polygon (if available). We can compute percentage of the delineated area that matches the reference (and vice versa). A high overlap (e.g., >95%) indicates good agreement . - Boundary distance : Sample points along one boundary and measure distance to the other boundary polygon. Compute mean and max discrepancy. - Stream network match : Delineate the stream network (using each tool’s flow accumulation and threshold) and compare to known streams (like NHD or a reference network). Metrics could include percentage of known stream length captured by the model network (true positive rate) and extra length of model streams not in reference (false positives). - Internal consistency : Verify that for a given pour point, the flow28 52 52 59 14



## Page 15

accumulation values or drainage areas reported by each tool are similar . If a tool produces a drainage area for an outlet that is, say, 1000 km², and another says 980 km² and reference is 990 km², that’s within a few percent – likely fine. But if one says 1200 km², that indicates it drew in an extra region erroneously. This check is essentially looking at numeric outputs (area, stream counts) as a sanity check. - Sensitivity/ robustness : We might vary an input slightly (e.g., add random noise to a DEM within ±1m) and see if a tool’s output changes significantly. This is a form of uncertainty test albeit limited. Tools that are robust should not produce wildly different watershed boundaries from a tiny perturbation. If we see high sensitivity, that might align with known issues (like in flat areas small changes can shift flow paths). We will also track qualitative aspects from outputs: e.g., does a tool produce spurious “single-cell” watersheds (maybe an artifact if threshold is too low)? Does the stream burning integration, if used, yield a visibly improved alignment or cause any distortions? Existing Benchmarks and Methodologies: While a comprehensive multi-tool benchmark has not been published (to our knowledge), pieces exist: - Some research papers serve as mini-benchmarks for algorithms (like the Prescott 2025 study comparing D8, MFD, D∞ on specific surfaces ). We can emulate their approach by including those algorithm tests in our framework. - The Hydrologic Modeler’s comparison : There have been presentations and reports (e.g., by USGS or EU researchers) comparing tools like TauDEM vs Arc Hydro vs others in specific watersheds, often focusing on whether the resulting stream networks match. We will glean any methods from such grey literature if available. - The BasinMaker 3.0 tool (Jones et al., 2021) mentioned in search results is a QGIS/GRASS toolbox for watershed delineation . It likely uses GRASS under the hood but could have introduced some standardized workflow. If documentation is available, it might highlight how they validate delineations or ensure consistency between QGIS and GRASS outputs . - Open-Source vs Commercial comparisons : Anectodal evidence from GIS forums suggests that open tools (GRASS, Whitebox) can replicate ArcGIS results. For instance, one Reddit thread asked for watershed software recommendations and people weighed in on pros/cons . The consensus often is that results are largely comparable if using similar algorithms. We will formally verify that by direct comparison. Quality Assurance Procedures: Ensuring the correctness of each tool’s output in our pipeline is crucial, especially since a “bug” in our use of a tool could be mistaken for a tool’s weakness. QA steps include: - Visual inspection of outputs : We will visually overlay each tool’s watershed delineation on a hillshade or contour map to see if it aligns with ridges and streams. Often, human eyes can quickly catch if one tool’s boundary crosses a ridge where it shouldn’t. This is a traditional but effective QA step used by hydrologists. - Cross-tool comparison : We can intersect the polygons from different tools and quantify their agreements and differences. If four tools agree on a boundary and one is an outlier in a certain area, that flags either an error in that tool or a scenario that tool handles differently (e.g., maybe GRASS sees a subtle alternative path due to not filling a sink while others filled it). Investigating such differences will deepen our understanding of each tool’s behavior . - Statistical validation : If we have multiple known outlet locations, we can produce a statistical summary: e.g., “In 50 test sub-basins, Tool A’s area was within 2% of reference on average, with a maximum error of 7%. Tool B’s area had a bias of +3%, etc.” This provides quantitative QA in aggregate, similar to how some studies report average discrepancy. - Reproducibility test : Run the same test multiple times to ensure results are stable and the process is deterministic (some parallel processes might introduce non-deterministic ordering, though results should be the same). Also, running on different machines or OS (via containers) to ensure environment doesn’t affect output. - Error logging : We will capture any error messages or warnings from the tools during execution. For example, GRASS might warn if52 103 104 105 15



## Page 16

there were too many sub-basins (we’d note that), or TauDEM might output “cannot allocate memory” if it fails – important to document. To facilitate these QA tasks, we may build small scripts (e.g., using geopandas or rasterio in Python) to automatically compute overlaps and differences between outputs and references. Finally, we will compile the benchmark results in a comparison matrix or report : - A table of features (as included above) for qualitative comparison. - Plots or charts of runtime vs data size for each tool. - A summary table of accuracy metrics (e.g., for each tool: average area error , boundary overlap %, etc., across test cases). - Example maps showing one region’s delineation by each tool (visual comparison, perhaps as an embedded image if allowed, or described). - Documentation of versions used: e.g., “TauDEM 5.3 (released 2020, with D∞ patch), GRASS GIS 8.2 (2023), WhiteboxTools 2.4.0 (2022), SAGA GIS 7.8.2 (2021), ArcGIS Pro 3.0 (2022) with Spatial Analyst” . Including version context is important as tools evolve (TauDEM, GRASS, Whitebox have seen improvements in the 2020s). This rigorous benchmarking approach draws on academic standards (reproducibility, use of standard datasets, multi-metric evaluation). It will not only reveal which tool excels in what aspect, but also help identify any gaps or anomalies for further investigation. The end goal is a validation framework that others can use to test additional tools or new versions, thereby contributing a systematic evaluation method to the community. 5. Emerging Trends and Future Directions Watershed delineation is a classical task, but ongoing research and technology trends are driving new developments. Here we highlight emerging tools, algorithms, and approaches that are shaping the future of watershed delineation, along with current research gaps and opportunities. New Algorithms and Tools: Beyond the established software we’ve analyzed, new algorithms continue to appear in literature. The IDS algorithm (Iterative Depth Slope) introduced by Prescott et al. (2025) is one such innovation – it couples flow routing with hydrodynamic principles to better simulate water distribution across complex surfaces . IDS is not yet in any mainstream tool, but it could be a candidate for future inclusion (perhaps in Whitebox or GRASS given their open nature). Its advantage is handling cases where water surface slope deviates from ground slope (think of very heavy rainfall causing ponding). Another development is the Automatic Outlet Relocation (AOR) algorithm by Xin et al. (2022), which isn’t a flow algorithm per se but a smart preprocessing step that adjusts user-specified outlet points to the nearest actual low point on a stream . AOR can then delineate watersheds extremely fast and accurately by eliminating common user error of misplacing outlets. This has been implemented in a research context (Python/C++ code) and showed dramatically improved speed and accuracy vs ArcGIS . We might see such functionality integrated into GIS tools (for example, future ArcGIS could incorporate automatic snap-to- stream for watershed delineation, or TauDEM could add an outlet correction utility). In terms of tools , one emerging player is Google Earth Engine (GEE) which now hosts high-resolution DEM data (like MERIT DEM) and provides some hydrological functions at global scale. GEE isn’t a specialized hydrology tool, but its ability to delineate watersheds via cloud computation on-demand is growing. There are scripts (e.g., by Upstream-Tech’s delineator project ) that use global flow direction grids (MERIT Hydro) to delineate any watershed online. This “watershed as a service” approach is gaining traction for web54106 107 34 108 16



## Page 17

applications (e.g., web-based watershed delineation tools that leverage precomputed global flow networks). While not a new algorithm, it’s a new paradigm: instant delineation via cloud APIs , trading some flexibility for convenience and scale. Another tool note: Manifold GIS 9 (commercial) was mentioned in community forums as an extremely fast GPU-accelerated GIS that excels at massive raster operations . It reportedly can perform flow accumulation much faster by using parallel GPU computations. While proprietary, it demonstrates the trend of leveraging modern hardware (GPUs) in GIS tasks that have traditionally been CPU-bound. Machine Learning Applications: Machine learning is being explored in hydrology, though not widely for the core delineation algorithm (since physics-based methods do well). However , ML has roles: - Hydrofeature extraction : Using deep learning on high-res satellite imagery or DEM derivatives to identify channel networks or watershed boundaries. For example, convolutional neural networks could potentially learn to detect ridges or stream lines, assisting delineation in tricky areas (such as urban or agricultural fields where DEM-based flow may be unclear). One 2022 study applied ML to assess watershed morphometry and could be extended to classifying terrain into drainage features. - Improving DEMs : ML has been used to improve DEM hydro-enforcement – e.g., learning to predict where culverts are under roads so that DEMs can be breached there. This indirectly aids delineation by producing more accurate DEM inputs. - Surrogate models : There’s research into training ML models to emulate hydrologic processes – for example, a deep learning model might quickly predict watershed boundaries given certain terrain descriptors, but this is experimental. More common is ML in rainfall-runoff modeling once watersheds are delineated . - Data-driven thresholding : ML could help decide the appropriate stream threshold by analyzing landscape characteristics and matching known stream maps – essentially a regression or classification to pick threshold that yields best match to observed streams. This could automate what is now often a manual calibration. Cloud and Scalable Computing: We touched on GEE and GPU acceleration. To elaborate, researchers Koytrakis et al. (2023) not only did uncertainty-aware delineation, but they implemented it as a multi-GPU program capable of handling country-wide datasets with Monte Carlo simulation . This is cutting- edge in terms of high-performance computing (HPC). It shows that embarrassingly parallel tasks like running many delineations on perturbed data can be massively sped up with GPUs. We might expect future open- source tools to incorporate GPU support for at least some operations (e.g., a GPU-accelerated flow accumulation). CUDA libraries for raster operations (like Horn’s algorithm for slope, etc.) exist; integrating those in mainstream GIS might happen. Cloud computing also enables scaling out: imagine splitting a continent’s DEM into tiles and processing them in parallel across a cluster – frameworks like Dask or Spark could orchestrate that. Some academic efforts (like automating global watershed delineation ) use such approaches to handle entire continents. Integration of Uncertainty and Hydrologic Variables: There’s a push to integrate more hydrologic realism into delineation. For example, accounting for land cover or soil in flow paths – currently delineation treats terrain as static and impervious. But in reality, high infiltration areas or dense vegetation might diminish surface flow connectivity. Some experimental studies incorporate a “effective drainage” concept where areas with certain soil can generate internal loss. This merges delineation with runoff modeling. We also see interest in dynamic delineation – watersheds that change with flood stage (floodplain connectivity) or human interventions (like gated canals). While our focus is static delineation, the future might see tools that can delineate contributing areas for different conditions (e.g., groundwater-driven vs surface-driven catchments).109 110 111 112 113 114 115 17



## Page 18

Current Research Gaps: Despite many tools, a few gaps exist which our benchmark can highlight: - Head- to-head tool evaluations are not commonly published. The community would benefit from more empirical comparisons (which is exactly what we aim to do). This can reveal if any tool consistently yields more accurate results or better performance in certain terrain. - Standardization of validation : As noted, there’s no single metric widely adopted. Research could establish a more formal standard – perhaps analogous to how classification has accuracy and F1-score, watershed delineation could have a well-defined “boundary match score.” Our work could contribute here by proposing a method for quantifying delineation accuracy. - Endorheic basins and complex hydrography : Tools typically delineate everything to an outlet. But what about areas with no outlet (closed basins)? Some tools treat them as separate watersheds ending in a sink, but validation of those is tricky since traditional methods expect an outlet. Research could improve delineation in such areas, perhaps by defining “sink watersheds” and how they connect to groundwater . - Interoperability and benchmarking frameworks : There isn’t a common framework to plug in a new algorithm and test it on standard data. Our multi-tool benchmark might be a step in this direction. Ideally, it could evolve into an open benchmark suite where new tools or versions (or even ML approaches) can be run and compared easily. This gap in the community means innovations sometimes aren’t tested against existing methods on equal footing. Future Opportunities: The field of digital terrain analysis is mature, but continues to evolve with data and computing advances. The proliferation of high-resolution DEMs (e.g., 1m LiDAR data) globally presents both an opportunity and challenge – enabling more detailed watershed analysis (tiny urban catchments, ephemeral gully networks) but requiring more robust processing techniques. There’s opportunity to combine multi-scale approaches : e.g., delineating large basins with coarse DEMs and then refining with nested high-res delineation for sub-basins. Our benchmark results might inspire such multi-scale workflows (e.g., use TauDEM for big picture, Whitebox for fine detail). We also foresee integration between surface and subsurface delineation . For example, defining watersheds for groundwater recharge areas which don’t always align with surface divides. Some current research (especially in karst regions) tries to map these using tracing and modeling, but a tool that could incorporate known subsurface flow paths into a “delineation” would be groundbreaking. Finally, as open-source tools continue to develop, we might expect convergence or collaboration : e.g., Whitebox and GRASS could share algorithms or both incorporate a new method like IDS. The hydrology GIS community is somewhat fragmented among software, but recognizing each other’s strengths (as we do in this analysis) could lead to cross-pollination – for instance, TauDEM’s parallel D∞ might be adopted in GRASS, or Whitebox’s breach method could be added to SAGA, etc. Our work identifying who does what best can guide such collaboration. Conclusion – Staying Ahead: Our benchmark will not only compare current capabilities but also be designed with these future trends in mind. By understanding emerging algorithms (like IDS, AOR) and computing methods (GPU, cloud) , we ensure the framework is extensible. We plan to keep the benchmark updated so that as new versions or tools appear , they can be evaluated under the same rigorous conditions. In doing so, we contribute a forward-looking resource to the community, helping both users and developers of watershed delineation tools to make informed decisions and innovations. 3473 18



## Page 19

Recommendations and Roadmap for Integration Drawing together all findings, we propose the following roadmap and recommendations for integrating multiple tools into our benchmark suite: Prioritize Open-Source Tools for Initial Integration: Start with WhiteboxTools and TauDEM as first-tier integrations. Both are open-source (MIT/BSD licenses) and offer high performance: Whitebox for its ease of use and rich algorithms, TauDEM for its parallel scalability. These two provide a strong combination – Whitebox’s multiple algorithms (D8, MFD, etc.) and TauDEM’s efficient D∞ and MPI capability cover many needs. Moreover , both have straightforward command-line usage; Whitebox adds a convenient Python API . By integrating these first, we can develop the core benchmarking workflow (data handling, metric computation) in a completely open environment. Include GRASS GIS for its Unique Capabilities: GRASS’s r .watershed brings the advantage of sink- free processing and proven accuracy in tricky conditions (e.g., forested flats) . It’s open-source but slightly more complex to script. We recommend integrating GRASS next, using either the PyGRASS API or by calling it through a Docker container . GRASS will allow us to test the impact of not filling sinks and to validate the claims that it outperforms traditional methods in low-slope areas . Integration effort is moderate – ensure the container and environment is set up, then call r.watershed with appropriate region and parameters. Incorporate SAGA GIS for Additional Algorithms: SAGA offers specialized flow algorithms (Triangular MFD, etc.) not found elsewhere. It’s also GPL open-source. We suggest integrating SAGA after GRASS. This will allow comparison of, say, SAGA’s Quinn et al. MFD vs Whitebox’s implementation, or SAGA’s “multiple downslope gradient” algorithm vs TauDEM’s D∞. The integration is via saga_cmd, which we can manage with prepared parameter sets. SAGA also provides alternative sink filling methods (Wang & Liu) we might want to test vs others. Optional: ArcGIS for completeness (secondary priority): Including ArcGIS (Arc Hydro tools or Spatial Analyst) is useful for context, but given licensing, we treat it as a special case. Perhaps we run ArcGIS analyses manually or on a separate machine and bring results in for comparison. The benchmark documentation can note ArcGIS Pro version and settings used (e.g., “MFD algorithm with force edge out = true”). If resources allow, automating ArcGIS via ArcPy is an option, but that requires a licensed environment. We can defer this to a later phase or a report appendix just to situate open- source results relative to the industry-standard software. Establish a Common Interface/Adapter Layer: Develop a small library of functions or scripts so that calling each tool for a given DEM/outlet is standardized. For example: run_taudem(dem, outlets, params) -> watersheds run_whitebox(dem, outlets, params) -> watersheds and so forth, where watersheds is a raster or vector delineation output. This abstraction will simplify adding new tools later (just add a new adapter) and makes the benchmark code cleaner . Ensure Consistent Preprocessing: Decide on a preprocessing pipeline that can be applied uniformly: e.g., Fill all DEMs using one method (or perhaps test both filled vs unfilled if that’s a comparison) before feeding to tools that require fill. Since GRASS doesn’t need fill, we might run GRASS on raw DEM, but run TauDEM/Whitebox on a filled DEM to see if results differ . This needs careful design. Possibly, do two rounds: one where all tools get a pre-filled DEM (so sink differences are eliminated), and another where GRASS and maybe Whitebox’s breach are allowed to shine on raw DEM.1. 79 2. 428 116 3. 117 118 4. 5. 6. 7. 8. 19



## Page 20

Develop Evaluation and Visualization Tools: Create scripts to calculate overlap, draw difference maps, etc., as described in the validation framework. This will automate the comparison after each tool runs. We should include statistical summaries and even simple plots (maybe Python matplotlib) to illustrate differences. For example, a bar chart of runtime for each tool per dataset, or a map highlighting where one tool’s boundary deviates from another’s. Test & Iterate on Small Basins: Start with a small watershed where we know the answer (maybe an outlet where the watershed is, say, 50 km² and easily inspected). Run all integrated tools there to verify they produce sensible, matching outputs. Resolve any discrepancies (could be a bug in how we call a tool). This shakedown will build confidence before applying to larger cases. Scale Up and Record Results: Apply the benchmark to larger and multiple basins as planned. Record all results carefully with citations of data sources and tool versions. Document Everything: As part of the project deliverables, produce thorough documentation (likely a report or whitepaper) summarizing the findings in the style of this analysis. Include the feature matrix (as above), the literature review summary, the methodology, and the results and interpretations. Make sure to cite relevant literature in context (as we have done here) to justify our methodology and to compare our findings to existing knowledge. The documentation will also serve as a basis if we aim to publish or share the benchmark results with the community (perhaps a conference paper or an online article). Timeline considerations: We should allocate time first for the deep research (completed with this document), then for implementation coding (perhaps a few weeks to get all tools working in tandem), then for running benchmarks on various datasets (could be time-consuming, especially if large – possibly use HPC time), and finally for analysis and writing. Based on the earlier provided timeline, after this Deep Research Phase , we move to Synthesis Phase (where we integrate with our project plans) and then Implementation Planning where specific technical roadmaps are drawn . We are on track, having gathered the necessary intel to inform those next steps. Key Recommendations: - Tool Selection: Focus on WhiteboxTools and TauDEM as primary engines in our benchmark due to their modern algorithms and performance. Use GRASS and SAGA to augment and cross- check special cases (ensuring no single method’s bias skews results). Use ArcGIS results as a reference baseline since it’s commonly used (ensuring our open-source tools meet or exceed its performance and accuracy). - Integration Ease: Whitebox’s Python API and TauDEM’s straightforward CLI mean we can relatively quickly have those running inside our Python-based framework . GRASS and SAGA require a bit more environment setup, but containerization will help. We should script installation or container builds so that setting up the entire suite on a new machine is as simple as running a Docker image or a conda environment. - Data and Terrain: Emphasize Mountain West data in tests (since that’s our immediate use- case) but include a variety to ensure generality. This dual focus (specific vs general) is reflected in our dataset choices. - Accuracy and Validation: Adopt multiple validation methods (area overlap, etc.) and lean on published standards where available (e.g., if USGS expects watershed area within 5% for Level-8 basins, use that as a target). If our benchmark shows some tool has difficulty meeting such standards, that’s important to note. - Reproducibility: Ensure all results can be reproduced by others by publishing the code and maybe the container . This is a “reproducible research” ethos that aligns with academic best practice and will increase confidence in our findings. By following this roadmap, we will create a robust multi-tool watershed delineation benchmark suite. This will directly guide our team in tool integration and provide the scientific community with a valuable comparative analysis. Ultimately, these efforts position our project to make a meaningful contribution – filling gaps in comparative evaluations, providing guidance on tool selection for different scenarios, and9. 10. 11. 12. 13. 119 79 20



## Page 21

potentially informing future development of these tools (as we can feed back findings to the developers of TauDEM, GRASS, Whitebox, etc., and perhaps collaborate on addressing any issues uncovered). hydrology.usu.edu https://hydrology.usu.edu/taudem/taudem5/TauDEM53CommandLineGuide.pdf r .watershed(1grass) — grass-doc — Debian testing — Debian Manpages https://manpages.debian.org/testing/grass-doc/r .watershed.1grass.en.html Why no need for "fill-sinks" when using r .watershed in GRASS QGIS? - Geographic Information Systems Stack Exchange https://gis.stackexchange.com/questions/375569/why-no-need-for-fill-sinks-when-using-r-watershed-in-grass-qgis Hydrological analysis - WhiteboxTools User Manual https://www.whiteboxgeo.com/manual/wbt_book/available_tools/hydrological_analysis.html Module Flow Accumulation (Top-Down) / SAGA-GIS Module Library Documentation (v2.3.0) https://saga-gis.sourceforge.io/saga_tool_doc/2.3.0/ta_hydrology_0.html Flow Direction (Raster Analysis)—ArcGIS Pro | Documentation https://pro.arcgis.com/en/pro-app/latest/tool-reference/raster-analysis/flow-direction.htm Module Fill Sinks (Wang & Liu) - SAGA GIS https://saga-gis.sourceforge.io/saga_tool_doc/2.1.4/ta_preprocessor_4.html SAGA flow Accumulation (top down) : r/QGIS - Reddit https://www.reddit.com/r/QGIS/comments/1jot9qu/saga_flow_accumulation_top_down/ Terrain Analysis Using Digital Elevation Models (TauDEM) https://hydrology.usu.edu/taudem/taudem3.0/ Burn streams into DEM https://jblindsay.github.io/ghrg/Whitebox/Help/BurnStreams.html Applying the Terrain Reconditioning Tools https://www.hec.usace.army.mil/confluence/display/HMSGUIDES/Applying+the+Terrain+Reconditioning+Tools? preview=%2F48136412%2F48136441%2Fimage2021-1-26_7-30-6.png David Tarboton: Hydrology Research Group-Terrain Analysis Using Digital Elevation Models (TauDEM) https://hydrology.usu.edu/taudem/taudem5/downloads5.0.html QGIS3.16/GRASS8.0 - "r .watershed" vs "r .terraflow" vs "r .stream.extract" : r/gis https://www.reddit.com/r/gis/comments/15uh43u/qgis316grass80_rwatershed_vs_rterraflow_vs/ Flow Accumulation (Spatial Analyst)—ArcGIS Pro | Documentation https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/flow-accumulation.htm Rapid Watershed Delineation Using an Automatic Outlet Relocation ... https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021WR031129 Limitations and Memory - WhiteboxTools User Manual https://www.whiteboxgeo.com/manual/wbt_book/limitations.html1 224 25 26 35 40 76 77 78 96 328 36 67 71 72 85 97 98116 415 16 51 75 5 610 11 12 79 80 781 82 83 84 91 94117 118 8 917 39 95 13 14 18 19 20 21 23 22 27 41 42 43 44 45 29 30 31109 32 33 92101 102 34 37 38 86 87 88 89 90 99100 21



## Page 22

WhiteboxTools v2.1 now released : r/gis - Reddit https://www.reddit.com/r/gis/comments/sinkep/whiteboxtools_v21_now_released/ ArcGIS Toolbox for WhiteboxTools v1.5.0 released w - Reddit https://www.reddit.com/r/gis/comments/nvwhn5/arcgis_toolbox_for_whiteboxtools_v150_released_w/ License - WhiteboxTools User Manual https://www.whiteboxgeo.com/manual/wbt_book/license.html ESurf - An evaluation of flow-routing algorithms for calculating contributing area on regular grids https://esurf.copernicus.org/articles/13/239/2025/ A complex synthetic surface for assessing flow direction algorithms ... https://www.sciencedirect.com/science/article/abs/pii/S0169555X24000308 An Improved Triangular Form‐Based Multiple Flow Direction ... https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021WR031706 Flow Direction function—ArcGIS Online | Documentation https://doc.arcgis.com/en/arcgis-online/analyze/flow-direction-raster-function.htm Rapid Watershed Delineation Using an Automatic Outlet Relocation ... https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2021WR031129 Comparison of Watershed Delineation Accuracy using Open Source ... https://www.researchgate.net/publication/ 351640393_Comparison_of_Watershed_Delineation_Accuracy_using_Open_Source_DEM_Data_in_Large_Area [PDF] A Comparative Study of Delineated Watersheds Using ASTER and ... https://ijger-ojs-txstate.tdl.org/ijger/article/download/110/77/162 Comparative study of agricultural parcel delineation deep learning ... https://www.sciencedirect.com/science/article/pii/S2772375525000668 A novel architecture for automated delineation of the agricultural ... https://www.sciencedirect.com/science/article/pii/S0168169925003710 A web-based tool for watershed delineation considering lakes and ... https://www.sciencedirect.com/science/article/abs/pii/S1364815224002937 Automating nested watershed delineation over the world ... https://www.tandfonline.com/doi/pdf/10.1080/17538947.2025.2513044 GIS-based spatial approaches to refining urban catchment ... https://link.springer .com/article/10.1007/s43832-024-00083-z High-performance watershed delineation algorithm for GPU using ... https://www.sciencedirect.com/science/article/abs/pii/S1364815222003139 A full graphics processing unit implementation of uncertainty-aware ... https://www.sciencedirect.com/science/article/abs/pii/S0098300414002027 WikiWatershed/docker-taudem - GitHub https://github.com/WikiWatershed/docker-taudem46 47 48 49 50 52 53 54 55106 56 57 58 59 60 62 63 61 64 65 66 68 69115 70 73 74 93 22



## Page 23

BasinMaker 3.0: A GIS toolbox for distributed watershed delineation ... https://www.sciencedirect.com/science/article/pii/S1364815223000749 Watershed Delineation and Analysis Software Recommendations https://www.reddit.com/r/Hydrology/comments/18hoe2i/watershed_delineation_and_analysis_software/ Rapid Watershed Delineation Using an Automatic Outlet Relocation ... http://ui.adsabs.harvard.edu/abs/2022WRR....5831129X/abstract Upstream-Tech/delineator: Watershed delineation python library https://github.com/Upstream-Tech/delineator Machine Learning-Based Assessment of Watershed Morphometry in ... https://www.mdpi.com/2073-445X/12/4/776 Machine learning classification approach for formation delineation at ... https://www.sciencedirect.com/science/article/pii/S2096249521000697 Scalable deep learning for watershed model calibration - Frontiers https://www.frontiersin.org/journals/earth-science/articles/10.3389/feart.2022.1026479/full A multi-GPU program for uncertainty-aware drainage basin delineation https://research.abo.fi/en/publications/a-multi-gpu-program-for-uncertainty-aware-drainage-basin-delineat research_brief_watershed_tools.md file://file-SYjZyuCCQ3x412d81DsySr103 104 105 107 108 110 111 112 113 114 119 23



