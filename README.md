# FLOWFINDER: Next-Generation Watershed Delineation with Unprecedented Reliability

A comprehensive watershed delineation tool and benchmark framework designed to establish new standards in accuracy, reliability, and systematic comparison. FLOWFINDER combines production-ready watershed delineation capabilities with the first standardized multi-tool benchmark framework for the hydrology research community.

![flow finder](images/flowfinder.png)

## ğŸ¯ Strategic Vision

**"Next-Generation Watershed Delineation with Unprecedented Reliability"**

FLOWFINDER represents a breakthrough in watershed delineation technology, achieving **100% validation success (51/51 checks)** while providing the first comprehensive benchmark framework for systematic tool comparison. Our mission is to establish new standards in watershed delineation through:

- **Production-ready tool** with unprecedented reliability validation
- **Comprehensive benchmark framework** for systematic multi-tool comparison
- **Mountain West terrain specialization** addressing geographic research gaps
- **Academic credibility** through rigorous validation and peer-reviewed methodology

## ğŸ† Key Differentiators

| Aspect | FLOWFINDER | TauDEM | GRASS GIS | WhiteboxTools |
|--------|------------|--------|-----------|---------------|
| **Reliability** | 100% validation (51/51) | Variable | Variable | Variable |
| **Benchmark Integration** | Native framework | External tools needed | Complex setup | Command-line focused |
| **Mountain West Focus** | Optimized | General purpose | General purpose | General purpose |
| **Modern Architecture** | Python + validation | MPI/C++ | C/Module system | Rust |

## ğŸ“‹ Prerequisites

- Python 3.8+
- FLOWFINDER CLI tool installed and accessible
- Access to USGS NHD+ HR data and 3DEP 10m DEM data
- 8GB+ RAM recommended for processing large datasets
- Docker (for TauDEM integration)
- GRASS GIS (for r.watershed comparison)

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd flowfinder

# Install dependencies
pip install -r requirements.txt

# Install FLOWFINDER
pip install flowfinder

# Copy environment template
cp .env.example .env
# Edit .env with your data paths and configuration
```

### 2. Configuration Setup

The system uses a hierarchical configuration architecture:

```bash
# Create configuration structure
mkdir -p config/{base,environments,tools,experiments,schemas}

# Environment-specific configurations
config/environments/development.yaml    # Local dev (10 basins)
config/environments/testing.yaml        # CI/testing (50 basins)  
config/environments/production.yaml     # Full-scale (500+ basins)

# Tool-specific configurations
config/tools/flowfinder.yaml            # FLOWFINDER settings
config/tools/taudem.yaml               # TauDEM MPI settings
config/tools/grass.yaml                # GRASS r.watershed settings
config/tools/whitebox.yaml             # WhiteboxTools settings
```

### 3. Data Preparation

Place your input datasets in the `data/` directory:

```
data/
â”œâ”€â”€ huc12_mountain_west.shp    # HUC12 boundaries for Mountain West
â”œâ”€â”€ nhd_hr_catchments.shp      # NHD+ HR catchment polygons
â”œâ”€â”€ nhd_flowlines.shp          # NHD+ HR flowlines
â””â”€â”€ dem_10m.tif               # 10m DEM mosaic or tiles
```

### 4. Run Single-Tool Benchmark

```bash
# Step 1: Generate stratified basin sample
python scripts/basin_sampler.py --config config/basin_sampler_config.yaml

# Step 2: Extract truth polygons
python scripts/truth_extractor.py --config config/truth_extractor_config.yaml

# Step 3: Run FLOWFINDER benchmark
python scripts/benchmark_runner.py \
    --sample basin_sample.csv \
    --truth truth_polygons.gpkg \
    --config config/benchmark_config.yaml \
    --outdir results/
```

### 5. Run Multi-Tool Comparison

```bash
# Using the new configuration system
python scripts/benchmark_runner_integrated.py \
    --environment development \
    --tools flowfinder,taudem \
    --experiment accuracy_comparison \
    --outdir results/multi_tool/
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ README.md                    # Project overview + setup
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ pyproject.toml              # Modern Python project config
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ .gitignore                  # Standard Python gitignore
â”‚
â”œâ”€â”€ config/                     # Hierarchical configuration system
â”‚   â”œâ”€â”€ base.yaml              # Foundation configurations
â”‚   â”œâ”€â”€ configuration_manager.py # Configuration inheritance system
â”‚   â”œâ”€â”€ environments/           # Environment-specific settings
â”‚   â”‚   â”œâ”€â”€ development.yaml   # Local development (10 basins)
â”‚   â”‚   â”œâ”€â”€ testing.yaml       # CI/testing (50 basins)
â”‚   â”‚   â””â”€â”€ production.yaml    # Full-scale (500+ basins)
â”‚   â”œâ”€â”€ tools/                  # Tool-specific configurations
â”‚   â”‚   â”œâ”€â”€ flowfinder.yaml    # FLOWFINDER settings
â”‚   â”‚   â”œâ”€â”€ taudem.yaml        # TauDEM MPI settings
â”‚   â”‚   â”œâ”€â”€ grass.yaml         # GRASS r.watershed settings
â”‚   â”‚   â””â”€â”€ whitebox.yaml      # WhiteboxTools settings
â”‚   â””â”€â”€ schemas/               # JSON Schema validation
â”‚
â”œâ”€â”€ scripts/                    # Core benchmark scripts
â”‚   â”œâ”€â”€ basin_sampler.py       # Stratified basin sampling
â”‚   â”œâ”€â”€ truth_extractor.py     # Truth polygon extraction
â”‚   â”œâ”€â”€ benchmark_runner.py    # FLOWFINDER accuracy testing
â”‚   â”œâ”€â”€ benchmark_runner_integrated.py # Multi-tool comparison
â”‚   â””â”€â”€ tool_adapters/         # Tool adapter implementations
â”‚
â”œâ”€â”€ data/                       # Input datasets (gitignored)
â”œâ”€â”€ results/                    # Output directory (gitignored)
â”œâ”€â”€ tests/                      # Unit tests
â”œâ”€â”€ docs/                       # Strategic and technical documentation
â”‚   â”œâ”€â”€ strategic_analysis_implementation_roadmap_v2.md # Strategic roadmap
â”‚   â”œâ”€â”€ multi_tool_integration_strategy.md # Integration strategy
â”‚   â”œâ”€â”€ strategic_analysis_assessment.md # Strategic evaluation
â”‚   â”œâ”€â”€ immediate_next_steps.md # Implementation priorities
â”‚   â”œâ”€â”€ configuration_architecture.md # Configuration system design
â”‚   â”œâ”€â”€ multi_tool_benchmark_architecture.md # Multi-tool framework
â”‚   â””â”€â”€ test_coverage/          # Test coverage documentation
â”‚
â””â”€â”€ notebooks/                  # Jupyter exploration
    â””â”€â”€ benchmark_analysis.ipynb
```

## ğŸ”§ Configuration Architecture

The system uses a **hierarchical configuration architecture** with inheritance:

### Configuration Hierarchy
```
Base Configurations â†’ Environment â†’ Tool â†’ Local Overrides
```

### Example Configuration Composition
```yaml
# Development FLOWFINDER experiment
inherits:
  - "base/regions.yaml#mountain_west_minimal"
  - "base/quality_standards.yaml#development_grade"
  - "environments/development.yaml"
  - "tools/flowfinder/base.yaml"
  - "experiments/accuracy_comparison.yaml"

overrides:
  basin_sampling:
    n_per_stratum: 1  # Minimal for dev
  benchmark:
    timeout_seconds: 30  # Quick timeout
```

### Tool Adapter Interface
```python
class ToolAdapter(ABC):
    @abstractmethod
    def delineate_watershed(self, pour_point: Point, dem_path: str) -> Tuple[Polygon, Dict]:
        """Delineate watershed and return polygon + performance metrics"""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """Check if tool is available on system"""
        pass
```

## ğŸ“Š Outputs

### Single-Tool Benchmark
- `benchmark_results.json`: Detailed per-basin metrics
- `accuracy_summary.csv`: Tabular results for analysis
- `benchmark_summary.txt`: Performance analysis and key findings

### Multi-Tool Comparison
- `multi_tool_results.json`: Comparative analysis across tools
- `performance_comparison.csv`: Runtime and memory comparisons
- `statistical_analysis.csv`: ANOVA, Tukey HSD, Kruskal-Wallis results
- `publication_figures/`: Publication-ready charts and graphs

## ğŸ¯ Success Metrics

### Technical Metrics
| Metric                    | Target                           |
| ------------------------- | -------------------------------- |
| FLOWFINDER IOU (mean)     | â‰¥ 0.90                           |
| FLOWFINDER IOU (90th percentile) | â‰¥ 0.95                       |
| Runtime (mean)            | â‰¤ 30 s                           |
| Configuration redundancy  | 90% reduction                    |
| Tool integration success  | 4 major tools integrated         |

### Academic Metrics
| Metric                    | Target                           |
| ------------------------- | -------------------------------- |
| Peer-reviewed publications | 2+ papers accepted               |
| Conference presentations  | 5+ presentations                 |
| Citations (2 years)       | 100+ citations                   |
| Framework adoption        | 3+ external research groups      |

### Community Metrics
| Metric                    | Target                           |
| ------------------------- | -------------------------------- |
| GitHub stars              | 500+ stars                       |
| FLOWFINDER downloads      | 1000+ downloads                  |
| External contributors     | 10+ contributors                 |
| Institutional adoptions   | 5+ adoptions                     |

## ğŸ§ª Testing

```bash
# Run unit tests
python -m pytest tests/

# Test configuration system
python test_configuration_system.py

# Test multi-tool integration
python test_integration.py

# Run with coverage
python -m pytest tests/ --cov=scripts --cov-report=html
```

## ğŸ“ˆ Analysis

Use the Jupyter notebook for detailed analysis:

```bash
# Start Jupyter
jupyter lab notebooks/

# Open benchmark_analysis.ipynb for interactive exploration
```

## ğŸ¯ Strategic Roadmap

### Phase 1: Foundation (Months 1-3) - CRITICAL
- âœ… **Configuration Architecture**: Hierarchical system implemented
- âœ… **FLOWFINDER Production**: 51/51 validation success achieved
- ğŸ”„ **Benchmark Framework MVP**: Multi-tool comparison operational
- ğŸ”„ **Research Foundation**: Literature review and gap analysis

### Phase 2: Tool Integration (Months 4-8) - HIGH PRIORITY
- ğŸ”„ **WhiteboxTools Integration**: Rust-based performance comparison
- ğŸ”„ **TauDEM Integration**: Academic gold standard validation
- ğŸ”„ **GRASS GIS Integration**: Comprehensive hydrological suite
- ğŸ”„ **SAGA GIS Integration**: European academic adoption

### Phase 3: Academic Impact (Months 9-12) - HIGH IMPACT
- ğŸ”„ **Comprehensive Benchmarking**: 25+ watersheds across terrain types
- ğŸ”„ **Statistical Analysis**: Publication-ready comparative results
- ğŸ”„ **Community Building**: Open source release and adoption
- ğŸ”„ **Academic Publications**: Peer-reviewed papers and presentations

## ğŸ“š Documentation

### Strategic Documents
- **[Strategic Roadmap](docs/strategic_analysis_implementation_roadmap_v2.md)**: Complete implementation plan with checkpoints
- **[Multi-Tool Integration Strategy](docs/multi_tool_integration_strategy.md)**: Research-based tool integration approach
- **[Strategic Assessment](docs/strategic_analysis_assessment.md)**: Comprehensive strategic evaluation
- **[Immediate Next Steps](docs/immediate_next_steps.md)**: Actionable implementation priorities

### Technical Documents
- **[Configuration Architecture](docs/configuration_architecture.md)**: Hierarchical configuration system design
- **[Multi-Tool Benchmark Architecture](docs/multi_tool_benchmark_architecture.md)**: Framework design and implementation
- **[Test Coverage](docs/test_coverage/)**: Comprehensive testing documentation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- USGS for NHD+ HR and 3DEP data
- FLOWFINDER development team
- Open source geospatial community
- Academic research community for validation and feedback

## ğŸ“ Support

For issues and questions:
- Check the [documentation](docs/)
- Review the [Strategic Roadmap](docs/strategic_analysis_implementation_roadmap_v2.md)
- See the [Multi-Tool Integration Strategy](docs/multi_tool_integration_strategy.md)
- Open an issue on GitHub

---

*"Reliability earns trust. Systematic comparison drives innovation."*

**FLOWFINDER: Establishing new standards in watershed delineation through unprecedented reliability and comprehensive benchmarking.** 