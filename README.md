# FLOWFINDER: Next-Generation Watershed Delineation with Unprecedented Reliability

A comprehensive watershed delineation tool and benchmark framework designed to establish new standards in accuracy, reliability, and systematic comparison. FLOWFINDER combines production-ready watershed delineation capabilities with the first standardized multi-tool benchmark framework for the hydrology research community.

![flow finder](images/flowfinder.png)

## üéØ Strategic Vision

**"Next-Generation Watershed Delineation with Unprecedented Reliability"**

FLOWFINDER represents a breakthrough in watershed delineation technology, achieving **100% validation success (51/51 checks)** while providing the first comprehensive benchmark framework for systematic tool comparison. Our mission is to establish new standards in watershed delineation through:

- **Production-ready tool** with unprecedented reliability validation
- **Comprehensive benchmark framework** for systematic multi-tool comparison
- **Mountain West terrain specialization** addressing geographic research gaps
- **Academic credibility** through rigorous validation and peer-reviewed methodology

## üèÜ Key Differentiators

| Aspect | FLOWFINDER | TauDEM | GRASS GIS | WhiteboxTools |
|--------|------------|--------|-----------|---------------|
| **Reliability** | 100% validation (51/51) | Variable | Variable | Variable |
| **Benchmark Integration** | Native framework | External tools needed | Complex setup | Command-line focused |
| **Mountain West Focus** | Optimized | General purpose | General purpose | General purpose |
| **Modern Architecture** | Python + validation | MPI/C++ | C/Module system | Rust |

## üìã Prerequisites

- Python 3.8+
- FLOWFINDER CLI tool installed and accessible
- Access to USGS NHD+ HR data and 3DEP 10m DEM data
- 8GB+ RAM recommended for processing large datasets
- Docker (for TauDEM integration)
- GRASS GIS (for r.watershed comparison)

## üöÄ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd flowfinder

# Install dependencies
pip install -r requirements.txt

# Install FLOWFINDER
pip install flowfinder

# Copy environment template
cp .env.example .env
# Edit .env with your data paths and configuration
```

### 2. Configuration Setup

The system uses a hierarchical configuration architecture:

```bash
# Create configuration structure
mkdir -p config/{base,environments,tools,experiments,schemas}

# Environment-specific configurations
config/environments/development.yaml    # Local dev (10 basins)
config/environments/testing.yaml        # CI/testing (50 basins)  
config/environments/production.yaml     # Full-scale (500+ basins)

# Tool-specific configurations
config/tools/flowfinder.yaml            # FLOWFINDER settings
config/tools/taudem.yaml               # TauDEM MPI settings
config/tools/grass.yaml                # GRASS r.watershed settings
config/tools/whitebox.yaml             # WhiteboxTools settings
```

### 3. Data Preparation

Place your input datasets in the `data/` directory:

```
data/
‚îú‚îÄ‚îÄ huc12_mountain_west.shp    # HUC12 boundaries for Mountain West
‚îú‚îÄ‚îÄ nhd_hr_catchments.shp      # NHD+ HR catchment polygons
‚îú‚îÄ‚îÄ nhd_flowlines.shp          # NHD+ HR flowlines
‚îî‚îÄ‚îÄ dem_10m.tif               # 10m DEM mosaic or tiles
```

### 4. Run Single-Tool Benchmark

```bash
# Step 1: Generate stratified basin sample
python scripts/basin_sampler.py --config config/basin_sampler_config.yaml

# Step 2: Extract truth polygons
python scripts/truth_extractor.py --config config/truth_extractor_config.yaml

# Step 3: Run FLOWFINDER benchmark
python scripts/benchmark_runner.py \
    --sample basin_sample.csv \
    --truth truth_polygons.gpkg \
    --config config/benchmark_config.yaml \
    --outdir results/
```

### 5. Run Multi-Tool Comparison

```bash
# Using the new configuration system
python scripts/benchmark_runner_integrated.py \
    --environment development \
    --tools flowfinder,taudem \
    --experiment accuracy_comparison \
    --outdir results/multi_tool/
```

## üìÅ Project Structure

```
‚îú‚îÄ‚îÄ README.md                    # Project overview + setup
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ pyproject.toml              # Modern Python project config
‚îú‚îÄ‚îÄ .env.example                # Environment template
‚îú‚îÄ‚îÄ .gitignore                  # Standard Python gitignore
‚îÇ
‚îú‚îÄ‚îÄ config/                     # Hierarchical configuration system
‚îÇ   ‚îú‚îÄ‚îÄ base.yaml              # Foundation configurations
‚îÇ   ‚îú‚îÄ‚îÄ configuration_manager.py # Configuration inheritance system
‚îÇ   ‚îú‚îÄ‚îÄ environments/           # Environment-specific settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ development.yaml   # Local development (10 basins)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ testing.yaml       # CI/testing (50 basins)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ production.yaml    # Full-scale (500+ basins)
‚îÇ   ‚îú‚îÄ‚îÄ tools/                  # Tool-specific configurations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ flowfinder.yaml    # FLOWFINDER settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ taudem.yaml        # TauDEM MPI settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grass.yaml         # GRASS r.watershed settings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ whitebox.yaml      # WhiteboxTools settings
‚îÇ   ‚îî‚îÄ‚îÄ schemas/               # JSON Schema validation
‚îÇ
‚îú‚îÄ‚îÄ scripts/                    # Core benchmark scripts
‚îÇ   ‚îú‚îÄ‚îÄ basin_sampler.py       # Stratified basin sampling
‚îÇ   ‚îú‚îÄ‚îÄ truth_extractor.py     # Truth polygon extraction
‚îÇ   ‚îú‚îÄ‚îÄ benchmark_runner.py    # FLOWFINDER accuracy testing
‚îÇ   ‚îú‚îÄ‚îÄ benchmark_runner_integrated.py # Multi-tool comparison
‚îÇ   ‚îî‚îÄ‚îÄ tool_adapters/         # Tool adapter implementations
‚îÇ
‚îú‚îÄ‚îÄ data/                       # Input datasets (gitignored)
‚îú‚îÄ‚îÄ results/                    # Output directory (gitignored)
‚îú‚îÄ‚îÄ tests/                      # Unit tests
‚îú‚îÄ‚îÄ docs/                       # Strategic and technical documentation
‚îÇ   ‚îú‚îÄ‚îÄ strategic_analysis_implementation_roadmap_v2.md # Strategic roadmap
‚îÇ   ‚îú‚îÄ‚îÄ multi_tool_integration_strategy.md # Integration strategy
‚îÇ   ‚îú‚îÄ‚îÄ strategic_analysis_assessment.md # Strategic evaluation
‚îÇ   ‚îú‚îÄ‚îÄ immediate_next_steps.md # Implementation priorities
‚îÇ   ‚îú‚îÄ‚îÄ configuration_architecture.md # Configuration system design
‚îÇ   ‚îú‚îÄ‚îÄ multi_tool_benchmark_architecture.md # Multi-tool framework
‚îÇ   ‚îî‚îÄ‚îÄ test_coverage/          # Test coverage documentation
‚îÇ
‚îî‚îÄ‚îÄ notebooks/                  # Jupyter exploration
    ‚îî‚îÄ‚îÄ benchmark_analysis.ipynb
```

## üîß Configuration Architecture

The system uses a **hierarchical configuration architecture** with inheritance:

### Configuration Hierarchy
```
Base Configurations ‚Üí Environment ‚Üí Tool ‚Üí Local Overrides
```

### Example Configuration Composition
```yaml
# Development FLOWFINDER experiment
inherits:
  - "base/regions.yaml#mountain_west_minimal"
  - "base/quality_standards.yaml#development_grade"
  - "environments/development.yaml"
  - "tools/flowfinder/base.yaml"
  - "experiments/accuracy_comparison.yaml"

overrides:
  basin_sampling:
    n_per_stratum: 1  # Minimal for dev
  benchmark:
    timeout_seconds: 30  # Quick timeout
```

### Tool Adapter Interface
```python
class ToolAdapter(ABC):
    @abstractmethod
    def delineate_watershed(self, pour_point: Point, dem_path: str) -> Tuple[Polygon, Dict]:
        """Delineate watershed and return polygon + performance metrics"""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """Check if tool is available on system"""
        pass
```

## üìä Outputs

### Single-Tool Benchmark
- `benchmark_results.json`: Detailed per-basin metrics
- `accuracy_summary.csv`: Tabular results for analysis
- `benchmark_summary.txt`: Performance analysis and key findings

### Multi-Tool Comparison
- `multi_tool_results.json`: Comparative analysis across tools
- `performance_comparison.csv`: Runtime and memory comparisons
- `statistical_analysis.csv`: ANOVA, Tukey HSD, Kruskal-Wallis results
- `publication_figures/`: Publication-ready charts and graphs

## üéØ Success Metrics

### Technical Metrics
| Metric                    | Target                           |
| ------------------------- | -------------------------------- |
| FLOWFINDER IOU (mean)     | ‚â• 0.90                           |
| FLOWFINDER IOU (90th percentile) | ‚â• 0.95                       |
| Runtime (mean)            | ‚â§ 30 s                           |
| Configuration redundancy  | 90% reduction                    |
| Tool integration success  | 4 major tools integrated         |

### Academic Metrics
| Metric                    | Target                           |
| ------------------------- | -------------------------------- |
| Peer-reviewed publications | 2+ papers accepted               |
| Conference presentations  | 5+ presentations                 |
| Citations (2 years)       | 100+ citations                   |
| Framework adoption        | 3+ external research groups      |

### Community Metrics
| Metric                    | Target                           |
| ------------------------- | -------------------------------- |
| GitHub stars              | 500+ stars                       |
| FLOWFINDER downloads      | 1000+ downloads                  |
| External contributors     | 10+ contributors                 |
| Institutional adoptions   | 5+ adoptions                     |

## üß™ Testing

```bash
# Run unit tests
python -m pytest tests/

# Test configuration system
python test_configuration_system.py

# Test multi-tool integration
python test_integration.py

# Run with coverage
python -m pytest tests/ --cov=scripts --cov-report=html
```

## üìà Analysis

Use the Jupyter notebook for detailed analysis:

```bash
# Start Jupyter
jupyter lab notebooks/

# Open benchmark_analysis.ipynb for interactive exploration
```

## üéØ Strategic Roadmap

### Phase 1: Foundation (Months 1-3) - CRITICAL
- ‚úÖ **Configuration Architecture**: Hierarchical system implemented
- ‚úÖ **FLOWFINDER Production**: 51/51 validation success achieved
- üîÑ **Benchmark Framework MVP**: Multi-tool comparison operational
- üîÑ **Research Foundation**: Literature review and gap analysis

### Phase 2: Tool Integration (Months 4-8) - HIGH PRIORITY
- üîÑ **WhiteboxTools Integration**: Rust-based performance comparison
- üîÑ **TauDEM Integration**: Academic gold standard validation
- üîÑ **GRASS GIS Integration**: Comprehensive hydrological suite
- üîÑ **SAGA GIS Integration**: European academic adoption

### Phase 3: Academic Impact (Months 9-12) - HIGH IMPACT
- üîÑ **Comprehensive Benchmarking**: 25+ watersheds across terrain types
- üîÑ **Statistical Analysis**: Publication-ready comparative results
- üîÑ **Community Building**: Open source release and adoption
- üîÑ **Academic Publications**: Peer-reviewed papers and presentations

## üìö Documentation

### Strategic Documents
- **[Strategic Roadmap](docs/strategic_analysis_implementation_roadmap_v2.md)**: Complete implementation plan with checkpoints
- **[Multi-Tool Integration Strategy](docs/multi_tool_integration_strategy.md)**: Research-based tool integration approach
- **[Strategic Assessment](docs/strategic_analysis_assessment.md)**: Comprehensive strategic evaluation
- **[Immediate Next Steps](docs/immediate_next_steps.md)**: Actionable implementation priorities

### Technical Documents
- **[Configuration Architecture](docs/configuration_architecture.md)**: Hierarchical configuration system design
- **[Multi-Tool Benchmark Architecture](docs/multi_tool_benchmark_architecture.md)**: Framework design and implementation
- **[Test Coverage](docs/test_coverage/)**: Comprehensive testing documentation

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- USGS for NHD+ HR and 3DEP data
- FLOWFINDER development team
- Open source geospatial community
- Academic research community for validation and feedback

## üìû Support

For issues and questions:
- Check the [documentation](docs/)
- Review the [Strategic Roadmap](docs/strategic_analysis_implementation_roadmap_v2.md)
- See the [Multi-Tool Integration Strategy](docs/multi_tool_integration_strategy.md)
- Open an issue on GitHub

---

*"Reliability earns trust. Systematic comparison drives innovation."*

**FLOWFINDER: Establishing new standards in watershed delineation through unprecedented reliability and comprehensive benchmarking.** 